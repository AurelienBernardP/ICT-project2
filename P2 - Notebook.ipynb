{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j7kUOJkq0GUo"
   },
   "source": [
    "# Project 2 - Source coding, data compression and channel coding\n",
    "\n",
    "The goal of this second project is to apply some of the principles seen in the lectures about source coding, data compression and channel coding. We ask you to write a brief report (pdf format) collecting your answers to the different questions. All codes must be written in Python inside this Jupyter. Note that you can not change the content of locked cells or import any extra Python library than the ones already imported (numpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ztp8uLg40GUt"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "In this project, you will need to use implement source coding algorithms to answer several questions. Therefore, in this first part, you are asked to write several functions that implement two of the  algorithms seen in the theoretical lectures and one new algorithm described in the project statement. Remember that you need to fill in this Jupyter Notebook to answer these questions. Pay particular attention to the required input and output format of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Hj-l1-GY0GUu"
   },
   "outputs": [],
   "source": [
    "# [Locked Cell] You can not import any extra Python library in this Notebook.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "B8U7YQaO0GUv"
   },
   "source": [
    "### Question 1\n",
    "Implement a function that returns a binary Huffman code for a given probability distribution. Give the main steps of your implementation. Verify your code on Exercise 7 of the second exercise session (TP2), and report the output of your code for this example. Explain how to extend your function to generate a Huffman code of any (output) alphabet size. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Huffman_code(probability_dict):\n",
    "    \n",
    "    sorted_dict=sorted(probability_dict.items(), key=lambda t: t[1])\n",
    "    it = iter(sorted_dict)\n",
    "    di = dict(sorted_dict) \n",
    "    \n",
    "    values_dict = di.values()\n",
    "    values= list(values_dict)\n",
    "    values.sort() \n",
    "    n=len(values)\n",
    "    list_steps=(-1)*np.ones((n,n-1)) \n",
    "    \n",
    "    final_dict = di.copy() \n",
    "    \n",
    "    j=0 \n",
    "    i=0\n",
    "    compteur=0\n",
    "    for j in range (n):\n",
    "        if i<n:\n",
    "            for k in range(0,i+1):\n",
    "                list_steps[k][j]= 1\n",
    "            if i+1<n:\n",
    "                list_steps[i+1][j]=0\n",
    "            if compteur>0 and i+2<n:\n",
    "                list_steps[i+2][j]=0\n",
    "        i+=1\n",
    "        if len(values)>3:\n",
    "            new_sum= values[0] + values[1]\n",
    "            values[1] = round(new_sum, 3)\n",
    "            del values[0]\n",
    "            next_sum=values[1] + values[2]\n",
    "\n",
    "            if round(new_sum +values[1], 3)> next_sum:\n",
    "                compteur+=1\n",
    "                values[2]=round(next_sum, 3)\n",
    "                del values[1]\n",
    "                for k in range(i+1,i+2):\n",
    "                    list_steps[k][j]=1\n",
    "                list_steps[i+2][j]=0\n",
    "                if len(values)>2 and values[1]>values[2]:\n",
    "                    list_steps[[i,i+1]]=list_steps[[i+1,i]] \n",
    "                    i+=1\n",
    "                values.sort()\n",
    "                \n",
    "        if j==n-3:\n",
    "            for k in range(n):\n",
    "                list_steps[k][j]=1\n",
    "            list_steps[-1][j]=0\n",
    "            break\n",
    "            \n",
    "                    \n",
    "\n",
    "            \n",
    "    transitory=np.zeros(n)\n",
    "    \n",
    "    for i in range (n):\n",
    "        l=0\n",
    "        for j in range (n-1):\n",
    "            if list_steps[i][j]==1:\n",
    "                transitory[i]=transitory[i] + 2**l\n",
    "                l+=1\n",
    "            elif list_steps[i][j]==0:\n",
    "                l+=1\n",
    "           \n",
    "          \n",
    "    for i in range (n):\n",
    "        transitory[i]=format(int(transitory[i]), 'b')\n",
    "        \n",
    "    i=0\n",
    "    for key in final_dict.keys():\n",
    "        final_dict[key]=str(int(transitory[i]))\n",
    "        i+=1\n",
    "        \n",
    "    return final_dict\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "final={\"A\": 0.21, \"B\":0.29,\"C\":0.06,\"D\":0.44}\n",
    "print(Huffman_code(final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_KjzF5nZ0GUw"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Given a sequence of symbols, implement a function that returns a dictionary and the encoded sequence using the on-line Lempel-Ziv algorithm (see State of the art in data compression, slide 50/53). Reproduce and report the example given in the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxyFyrmh0GUx"
   },
   "outputs": [],
   "source": [
    "def LZ_online(sequence):\n",
    "    list_symbols=[]\n",
    "    list_symbols_set = set()\n",
    "    dictionary=dict()\n",
    "    dictionary['']=(0,'')\n",
    "    i=-1\n",
    "    j=0\n",
    "    for x in sequence:\n",
    "        i+=1\n",
    "        for j in range(1,len(sequence)):\n",
    "            word=sequence[i:i+j]\n",
    "            if word not in list_symbols_set:\n",
    "                list_symbols.append(word)\n",
    "                list_symbols_set.add(word)\n",
    "                break\n",
    "        i+=j-1\n",
    "    list_symbols.remove('')\n",
    "\n",
    "    items=np.arange(1,len(list_symbols)+1)\n",
    "    binary = []\n",
    "    number = []\n",
    "    encoded_seq = \"\"\n",
    "\n",
    "    for item in items:\n",
    "        binary.append(format(item, '08b'))\n",
    "        number.append(int(np.ceil(np.log2(item))))\n",
    "        \n",
    "\n",
    "    for indice, x in enumerate(list_symbols):\n",
    "        if len(x)<=1:\n",
    "            nb=number[indice]\n",
    "            if nb==0:\n",
    "                dictionary[x]=(items[indice],x)\n",
    "            else:\n",
    "                dictionary[x]=(items[indice],\"0\"+x)\n",
    "           \n",
    "        else:\n",
    "            prefix=x[:-1]\n",
    "            ind=list_symbols.index(prefix)\n",
    "            dictionary[x]=(items[indice], str((binary)[ind])[-number[indice]:]+x[-1])\n",
    "            \n",
    "        encoded_seq += (dictionary[x])[1]    \n",
    "            \n",
    "\n",
    "    return dictionary, encoded_seq\n",
    "\n",
    "LZ_online(\"1011010100010\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UG7cwbf50GUx"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Implement a function that returns the encoded sequence using the LZ77 algorithm as described by the algorithm below given an input string and a sliding window size l. Reproduce the example given in Figure 2 with window_size=7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LZ77(sequence, window_size=7):\n",
    "    input_size=len(sequence)-window_size\n",
    "    input=sequence[:input_size]\n",
    "    sliding=\"\"\n",
    "    sliding_size=window_size\n",
    "    encoded=[]\n",
    "    i=1\n",
    "    while(len(input)>0):\n",
    "        prefix=input\n",
    "        while prefix not in sliding and len(prefix)>0:\n",
    "            prefix=prefix[:-1]\n",
    "        \n",
    "        if prefix in sliding and len(prefix)>0:\n",
    "            d=sliding_size-(len(sliding) - sliding[::-1].index(prefix[::-1]) - len(prefix))\n",
    "            p=len(prefix)\n",
    "            c=input[p]\n",
    "        else:\n",
    "            d=0\n",
    "            p=0\n",
    "            c=input[0]\n",
    "        i+=1\n",
    "        encoded.append((d,p,c))\n",
    "        for y in range(p+1):\n",
    "            sliding= sliding + input[y]\n",
    "        sliding_size=len(sliding)\n",
    "        input=sequence[sliding_size:input_size+sliding_size]\n",
    "    return \"\".join([str(_) for _ in encoded]) #is it the right format? \n",
    "        \n",
    "\n",
    "LZ77(\"abracadabrad\", window_size=7)       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EG1vVgUg0GUz"
   },
   "outputs": [],
   "source": [
    "# [Locked Cell] Evaluation of your functions by the examiner. \n",
    "# You don't have access to the evaluation, this will be done by the examiner.\n",
    "# Therefore, this cell will return nothing for the students.\n",
    "import os\n",
    "if os.path.isfile(\"private_evaluation.py\"):\n",
    "    from private_evaluation import unit_tests\n",
    "    unit_tests(Huffman_code, LZ_online, LZ77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "znaBCYTG0GU0"
   },
   "source": [
    "## Source coding and reversible (lossless) data compression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F_fTEp10GU0"
   },
   "outputs": [],
   "source": [
    "#import pyplot to make plots for questions like question 7\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Opening the files and put them into one line string\n",
    "text = ''\n",
    "with open('morse.txt', 'r') as file:\n",
    "    morse_text = file.read().replace('\\n', '')\n",
    "\n",
    "alphabet_text = ''\n",
    "with open('text.txt', 'r') as file:\n",
    "    alphabet_text = file.read().replace('\\n', '')\n",
    "\n",
    "def question5(text):\n",
    "\n",
    "    occurency_dict = {}\n",
    "    #loop over text and count occurrences.\n",
    "    for i in text:\n",
    "        if i in occurency_dict:\n",
    "            occurency_dict[i] = occurency_dict[i] + 1\n",
    "        else:\n",
    "            occurency_dict[i] = 1\n",
    "\n",
    "\n",
    "    #loop over symbols to compute their probability approximation\n",
    "    proba_dict = {}\n",
    "    for i in occurency_dict:\n",
    "        proba_dict[i] = occurency_dict[i]/len(text)\n",
    "        print(\"Probability of symbol '\" + i + \"' is =\" + str(proba_dict[i]))\n",
    "\n",
    "    #get huffman dictionary and then code the text\n",
    "    huffman_dict = Huffman_code(proba_dict)\n",
    "    print(\"bin huffman code for given text : \" + str(huffman_dict))\n",
    "\n",
    "    coded_text = ''\n",
    "    for i in text:\n",
    "        coded_text += huffman_dict[i]\n",
    "\n",
    "    print('Text length = ' + str(len(text)))\n",
    "    print('Coded text length = ' + str(len(coded_text)))\n",
    "    print('Using the huffman code the compression rate is :' + str(len(coded_text)/len(text)) + 'bits per symbol')\n",
    "    \n",
    "\n",
    "    return proba_dict,huffman_dict,coded_text\n",
    "\n",
    "def question6(char_proba_dict,huffman_dict,coded_text,original_text):\n",
    "\n",
    " #weighted average length of huffman code\n",
    "    expected_average_code_len = 0.0\n",
    "    for i in huffman_dict:\n",
    "        expected_average_code_len += char_proba_dict[i] * len(huffman_dict[i])\n",
    "\n",
    "    print('The expected average code length of the produced huffman code is =' + str(expected_average_code_len) + ' bits per symbol')\n",
    "\n",
    "    empirical_average_code_len = len(coded_text)/len(original_text)\n",
    "\n",
    "    print('The empirical average code length of the produced huffman code is =' + str(empirical_average_code_len) + ' bits per symbol')\n",
    "\n",
    "    #theoretical bound is \n",
    "    theoretical_bound = 0.0\n",
    "    for i in char_proba_dict:\n",
    "        theoretical_bound += char_proba_dict[i] * np.log2(1/char_proba_dict[i]) # H(s)\n",
    "\n",
    "    print('The bounds for the average length is  :' + str(theoretical_bound) + \" <= average word length < \" + str(theoretical_bound + 1))\n",
    "\n",
    "    return\n",
    "\n",
    "def question7(original_text, huffman_code_dict, upper_text_len_bound = 500, step = 1):\n",
    "\n",
    "    emp_averages_code_lengths = np.zeros((len(original_text)))\n",
    "\n",
    "    for i in range(1,upper_text_len_bound,step):\n",
    "        print('iteration ' + str(i) + ' of ' + str(upper_text_len_bound), end =\"\\r\")\n",
    "        code = ''\n",
    "        for j in original_text[0:i]:\n",
    "            code += huffman_code_dict[j]\n",
    "\n",
    "        emp_averages_code_lengths[i] = len(code)/i\n",
    "    print('\\n Finished!', end =\"\\n\")\n",
    "\n",
    "    plt.plot(np.arange(start = 0,stop =upper_text_len_bound),emp_averages_code_lengths[0:upper_text_len_bound])\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def question11():\n",
    "\n",
    "    return\n",
    "\n",
    "def question12():\n",
    "\n",
    "    return\n",
    "\n",
    "def question14(alphabet_text):\n",
    "    print(\"#############################\")\n",
    "    print(\"For original alphabet text:\")\n",
    "\n",
    "    alphabet_char_probabilities, alphabet_huffman_dict, alphabet_huffman_coded = question5(alphabet_text)\n",
    "    question6(alphabet_char_probabilities, alphabet_huffman_dict, alphabet_huffman_coded, alphabet_text)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "############### Q5 \n",
    "\n",
    "print(\"#############################\")\n",
    "print(\"For Morse text :\")\n",
    "morse_char_probabilities, morse_huffman_dict, morse_huffman_coded = question5(morse_text)\n",
    "\n",
    "################ Q6\n",
    " \n",
    "question6(morse_char_probabilities, morse_huffman_dict, morse_huffman_coded, morse_text)\n",
    "\n",
    "################ Q7\n",
    "\n",
    "question7(morse_text,morse_huffman_dict)\n",
    "\n",
    "################ Q8\n",
    "'''\n",
    "_,lempel_ziv_coded_morse = LZ_online(morse_text)\n",
    "\n",
    "print('Length of lempel-ziv compressed code is :' + str(len(lempel_ziv_coded_morse)))\n",
    "print('The compression rate of the Lempel-ziv method ire =' + str(len(lempel_ziv_coded_morse)/len(morse_text)))\n",
    "\n",
    "################ Q9\n",
    "'''\n",
    "lz77_coded_morse = LZ77(morse_text,7)\n",
    "\n",
    "print('Length of LZ77 compressed code is :' + str(len(lz77_coded_morse)))\n",
    "print('The compression rate of the LZ77 method is =' + str(len(lz77_coded_morse)/len(morse_text)))\n",
    "\n",
    "################ Q10\n",
    "\n",
    "#first way : apply huffman to get code and then, LZ77 to get smaller code\n",
    "    # main advantage, replace long coded symbols that may happen often by just two numerical symbols. More advantageous when high entropy in text and therefore codes are longueur\n",
    "\n",
    "#second way : LZ77 and then huffman on the pairs (x,y) and original symbols\n",
    "    # main advantage if the repetition of prefixes are mainly close together it reduces the code from a numeric pair to a couple of bits. more advantageous when low entropy in text.\n",
    "\n",
    "################# Q11\n",
    "\n",
    "#TODO:Second option seems more effective than first option . after looking it up it turns out that this method has a name. It's called DEFLATE.\n",
    "\n",
    "################# Q12\n",
    "\n",
    "\n",
    "################# Q13\n",
    "\n",
    "# In a text whole word repetitions are very frequent. Specially with connecting words. There are other less frequent repetitions like character names as mentioned in the statement. \n",
    "# It would therefore make sense to encode syllables (2-3 letters combinations) of the english language instead of single letters. Encoding full words would lead to very large dictionaries with some words only occuring a couple times or not at all.\n",
    "# This would add a considerable overhead too and still be inefficient to transmit or save texts.\n",
    "\n",
    "# The previously mentioned second way of combining the LZ77 and huffman algorithm is good at finding these small close together repetitions and encoding them in an efficient manner. This algorithms is also very general and\n",
    "# fast to decode and relatively fast to encode.\n",
    "\n",
    "\n",
    "################# Q14\n",
    "\n",
    "question14(alphabet_text)\n",
    "################ Q 15\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arr1rcE65c6K"
   },
   "source": [
    "## Channel coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLwLdqlh5qE5"
   },
   "outputs": [],
   "source": [
    "# Write here your codes for questions 16 to 21 (you may delete this comment)\n",
    "# From here, you may import either opencv (cv2) or the Python Imaging Library (PIL), but no other extra libraries.\n",
    "\n",
    "from PIL import Image,ImageOps\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def read_greyscale_image(path):\n",
    "\n",
    "    img = Image.open(path) \n",
    "    if img is None:\n",
    "        sys.exit(\"Could not read the image.\")\n",
    "\n",
    "    grey_scale = ImageOps.grayscale(img)\n",
    "    display(grey_scale) \n",
    "\n",
    "    return grey_scale\n",
    "\n",
    "def save_image(img,path):\n",
    "    if img is None or path is None:\n",
    "        sys.exit(\"Could not save Image.\")\n",
    "\n",
    "    img.save(path, \"PNG\")\n",
    "\n",
    "    return\n",
    "\n",
    "def encode_image(img):\n",
    "    return np.matrix.flatten(np.unpackbits(np.asarray(img),axis = 1))\n",
    "\n",
    "def decode_image(image_as_bits,shape):\n",
    "    return np.reshape(np.packbits(image_as_bits,axis = 0),shape)\n",
    "\n",
    "def hamming_sequence_encoding(sequence):\n",
    "    #pad the sequence to be a multiple of 4\n",
    "    padding_len = len(sequence) % 4\n",
    "    np.append(sequence,np.zeros(padding_len, dtype=np.int8))\n",
    "\n",
    "    #apply hamming code to every 4 char\n",
    "    hamming_sequence = np.zeros(len(sequence)//4*7,dtype=np.int8)\n",
    "    for i in range(0,len(sequence),4):\n",
    "        code = hamming_code(sequence[i:i+4])\n",
    "\n",
    "        hamming_sequence[((i//4)*7):((i//4)*7)+7] = code\n",
    "\n",
    "    return hamming_sequence\n",
    "\n",
    "def hamming_sequence_decoding(sequence,original_nb_bits):\n",
    "    decoded_sequence = np.zeros(len(sequence)//7 * 4,dtype=np.int8)\n",
    "    nb_corrections = 0 \n",
    "\n",
    "    for i in range(0,len(sequence),7):\n",
    "        decoded_bits = decode_hamming(sequence[i:i+7])\n",
    "        if np.array_equal(decoded_bits, sequence[i:i+4]):\n",
    "            None\n",
    "        else :\n",
    "            nb_corrections += 1\n",
    "\n",
    "        decoded_sequence[(i//7) *4 : ((i//7) * 4) + 4] = decoded_bits\n",
    "        \n",
    "    #remove padding done at source\n",
    "    return decoded_sequence[0:original_nb_bits]\n",
    "\n",
    "def sequence_through_channel(original_sequence):\n",
    "    noisy_sequence = original_sequence\n",
    "\n",
    "    for i, bit in enumerate(noisy_sequence):\n",
    "        noisy_sequence[i] = noisy_channel(bit)\n",
    "\n",
    "    return noisy_sequence\n",
    "\n",
    "def noisy_channel(bit):\n",
    "    if np.random.rand() > 0.01 :\n",
    "        return bit\n",
    "    else:\n",
    "        return (bit + 1) % 2\n",
    "\n",
    "def hamming_code(bits):\n",
    "    if len(bits) != 4:\n",
    "        print('error: wrong number of bits given')\n",
    "        return None\n",
    "\n",
    "    parity = np.zeros(3,dtype=np.int8)\n",
    "    for i in range(len(parity)):\n",
    "        parity[i] = (bits[i%4] + bits[(i+1)%4] + bits[(i+2)%4]) % 2\n",
    "\n",
    "    code = np.append(bits,parity)\n",
    "    return code\n",
    "\n",
    "def decode_hamming(code):\n",
    "    if len(code) != 7:\n",
    "        print('error: wrong number of bits given')\n",
    "        return None\n",
    "\n",
    "    bits = np.copy(code[0:4])\n",
    "    received_parity = code[4:7]\n",
    "    computed_parity = (hamming_code(code[0:4]))[4:7]\n",
    "\n",
    "    syndrome = np.zeros(3,dtype=np.int8)\n",
    "    nb_errors = 0 \n",
    "\n",
    "    for i in range(len(received_parity)):\n",
    "\n",
    "        if(computed_parity[i] != received_parity[i]):\n",
    "            syndrome[i] = 1\n",
    "            nb_errors += 1\n",
    "\n",
    "    if nb_errors == 3:\n",
    "        bits[2] = (code[2] + 1) % 2\n",
    "\n",
    "    if nb_errors == 2:\n",
    "        if syndrome[0] and syndrome[1]:\n",
    "            bits[1] = (code[1] + 1) % 2\n",
    "\n",
    "        if syndrome[1] and syndrome[2]:\n",
    "            bits[3] = (code[3] + 1) % 2\n",
    "\n",
    "        if syndrome[2] and syndrome[0]:\n",
    "            bits[0] = (code[0] + 1) % 2\n",
    "\n",
    "    return bits\n",
    "\n",
    "\n",
    "def number_of_differences(seq1,seq2):\n",
    "    nb_diff = 0\n",
    "    for i in range(len(seq1)):\n",
    "        if seq1[i] != seq2[i]:\n",
    "            nb_diff += 1\n",
    "    \n",
    "    return nb_diff\n",
    "\n",
    "def naive_hamming_seq_decoding(sequence,original_nb_bits):\n",
    "\n",
    "    decoded_sequence = np.zeros(len(sequence)//7 * 4,dtype=np.int8)\n",
    "\n",
    "    for i in range(0,len(sequence),7):\n",
    "        decoded_sequence[(i//7) *4 : ((i//7) * 4) + 4] = sequence[i:i+4]\n",
    "        \n",
    "    #remove padding done at source\n",
    "    return decoded_sequence[0:original_nb_bits]\n",
    "\n",
    "######################################## Code to answer the questions ##############\n",
    "\n",
    "#### 16 :Load image and show ####################\n",
    "\n",
    "original_image = read_greyscale_image(\"image.png\")\n",
    "\n",
    "#### 17 :Encode image using 1byte/pixel #########\n",
    "\n",
    "image_as_sequence = encode_image(original_image)\n",
    "\n",
    "#### 18 :Simulate channel and decode sequence ###\n",
    "im_width, im_height = original_image.size\n",
    "\n",
    "after_channel = decode_image(sequence_through_channel(image_as_sequence),(im_height,im_width))\n",
    "display(Image.fromarray(after_channel))\n",
    "\n",
    "save_image(Image.fromarray(after_channel),'noisy.png')\n",
    "\n",
    "#### 19 :Encode image using Hamming code #########\n",
    "hamming_sequence = hamming_sequence_encoding(image_as_sequence)\n",
    "\n",
    "#### 20 :Simulate channel on Hamming sequence ####\n",
    "hamming_after_channel = sequence_through_channel(hamming_sequence)\n",
    "\n",
    "decoded_hamming = hamming_sequence_decoding(hamming_after_channel,len(image_as_sequence))\n",
    "naive_decoded_hamming = naive_hamming_seq_decoding(hamming_after_channel,len(image_as_sequence))\n",
    "\n",
    "print(\"errors without hamming decoding compared to original image = \" + str(number_of_differences(image_as_sequence, naive_decoded_hamming)))\n",
    "print(\"errors with  hamming decoding compared to original image = \" + str(number_of_differences(image_as_sequence, decoded_hamming)))\n",
    "\n",
    "display(Image.fromarray(decode_image(decoded_hamming,(im_height,im_width))))\n",
    "save_image(Image.fromarray(decode_image(decoded_hamming,(im_height,im_width))),'postHamming_decoded.png')\n",
    "save_image(Image.fromarray(decode_image(naive_decoded_hamming,(im_height,im_width))),'naive_Hamming_decoding.png')\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "P2 - Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
