{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j7kUOJkq0GUo"
   },
   "source": [
    "# Project 2 - Source coding, data compression and channel coding\n",
    "\n",
    "The goal of this second project is to apply some of the principles seen in the lectures about source coding, data compression and channel coding. We ask you to write a brief report (pdf format) collecting your answers to the different questions. All codes must be written in Python inside this Jupyter. Note that you can not change the content of locked cells or import any extra Python library than the ones already imported (numpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ztp8uLg40GUt"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "In this project, you will need to use implement source coding algorithms to answer several questions. Therefore, in this first part, you are asked to write several functions that implement two of the  algorithms seen in the theoretical lectures and one new algorithm described in the project statement. Remember that you need to fill in this Jupyter Notebook to answer these questions. Pay particular attention to the required input and output format of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Hj-l1-GY0GUu"
   },
   "outputs": [],
   "source": [
    "# [Locked Cell] You can not import any extra Python library in this Notebook.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "B8U7YQaO0GUv"
   },
   "source": [
    "### Question 1\n",
    "Implement a function that returns a binary Huffman code for a given probability distribution. Give the main steps of your implementation. Verify your code on Exercise 7 of the second exercise session (TP2), and report the output of your code for this example. Explain how to extend your function to generate a Huffman code of any (output) alphabet size. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Huffman_code(probability_dict):\n",
    "    \n",
    "    sorted_dict=sorted(probability_dict.items(), key=lambda t: t[1])\n",
    "    it = iter(sorted_dict)\n",
    "    di = dict(sorted_dict) \n",
    "    \n",
    "    values_dict = di.values()\n",
    "    values= list(values_dict)\n",
    "    values.sort() \n",
    "    n=len(values)\n",
    "    rebours=n\n",
    "    list_steps=(-1)*np.ones((n,n)) \n",
    "    compteur=np.zeros((len(values), len(values))) \n",
    "    final_dict = di.copy() \n",
    "    old_value_max=[]\n",
    "    all_max=[]\n",
    "    j=0\n",
    "    \n",
    "    while j<n-2 and rebours>1:\n",
    "        \n",
    "        masked_values1 = np.ma.masked_equal(values, 0, copy=False)\n",
    "        min1=np.min(masked_values1)\n",
    "        indice_min1=values.index(min1)\n",
    "        b = masked_values1[np.arange(len(masked_values1))!=indice_min1]\n",
    "        min2=np.min(b)\n",
    "        if min2==min1: \n",
    "            min1_repeat  = [index for (index, item) in enumerate(values) if item == min1]\n",
    "            indice_min2=min1_repeat[1]\n",
    "        else:\n",
    "            indice_min2=values.index(min2)\n",
    "        indice_max=max(indice_min1,indice_min2)\n",
    "        \n",
    "        indice_min=min(indice_min1, indice_min2)\n",
    "        \n",
    "        if (indice_min in old_value_max or indice_max in old_value_max):\n",
    "            j+=1\n",
    "            old_value_max=[]\n",
    "            all_max.append(indice_max)\n",
    "        \n",
    "        if len(all_max)>1 and compteur[indice_max][indice_max]>=1 and compteur[all_max[-2]][all_max[-2]]>=1 and all_max[-2]>=indice_max :\n",
    "            indice_max, indice_min = indice_min, indice_max \n",
    "            \n",
    "        \n",
    "        new_sum= values[indice_min] + values[indice_max]\n",
    "        old_value_max.append(indice_max)\n",
    "        values[indice_max] = round(new_sum, 12)\n",
    "        values[indice_min] = 0\n",
    "        rebours-=1\n",
    "  \n",
    "        \n",
    "        if compteur[indice_max][indice_max]==0:\n",
    "            compteur[indice_max][indice_max]=1\n",
    "        else:\n",
    "            for m in range(len(values)):\n",
    "                if compteur[indice_max][m]==1:\n",
    "                    compteur[indice_max][m]+=1\n",
    "        for m in range(len(values)):\n",
    "            if compteur[indice_min][m]!=0:\n",
    "                compteur[indice_max][m]+=1\n",
    "        compteur[indice_max][indice_min]=1\n",
    "\n",
    "        last=0\n",
    "\n",
    "        \n",
    "        for k in range(n):\n",
    "            if compteur[indice_max][k]==1:\n",
    "                list_steps[k][j]=1\n",
    "                last=k\n",
    "            elif compteur[indice_max][k]>1:\n",
    "                list_steps[k][j]=0\n",
    "                last=k\n",
    "        if rebours>0:\n",
    "            list_steps[last][j]=0\n",
    "\n",
    "\n",
    "    transitory=(-1)*np.ones(n, dtype=int)\n",
    "    transitory=transitory.astype(str)\n",
    "    \n",
    "    for i in range (n):\n",
    "        for j in range(n-1, -1, -1):\n",
    "            if list_steps[i][j]!=-1:\n",
    "                if transitory[i]=='-1':\n",
    "                    transitory[i]=str(int(list_steps[i][j]))\n",
    "                else: \n",
    "                    transitory[i]=transitory[i]+str(int(list_steps[i][j]))\n",
    "\n",
    "        \n",
    "    i=0\n",
    "    for key in final_dict.keys():\n",
    "        final_dict[key]=transitory[i]\n",
    "        i+=1\n",
    "            \n",
    "    \n",
    "    return final_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final={'h': 0.05460697048337416,\n",
    "  'a': 0.06444180349736849,\n",
    "  'r': 0.052496907666561565,\n",
    "  'y': 0.020901748684242438,\n",
    "  ' ': 0.1880114476971211,\n",
    "  'p': 0.013412238364337513,\n",
    "  'o': 0.06340132424631952,\n",
    "  't': 0.07033057650796731,\n",
    "  'e': 0.09671121243724382,\n",
    "  'n': 0.0528970919938881,\n",
    "  'd': 0.04030462516068007,\n",
    "  's': 0.047786859401906336,\n",
    "  'c': 0.016196551138706314,\n",
    "  'b': 0.012922315733307464,\n",
    "  'j': 0.0008998083965947952,\n",
    "  'k': 0.009720841114695254,\n",
    "  'w': 0.02036574422158085,\n",
    "  'l': 0.03540539885037957,\n",
    "  'i': 0.05045475491741651,\n",
    "  'g': 0.020906599403361547,\n",
    "  'v': 0.007040818801387305,\n",
    "  'm': 0.0179428100215857,\n",
    "  'u': 0.02364968106521792,\n",
    "  'f': 0.016608862263830612,\n",
    "  'x': 0.0009240619921903423,\n",
    "  'z': 0.0006402949237224419,\n",
    "  'q': 0.0010186510150129756}\n",
    "print(Huffman_code(final))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_KjzF5nZ0GUw"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Given a sequence of symbols, implement a function that returns a dictionary and the encoded sequence using the on-line Lempel-Ziv algorithm (see State of the art in data compression, slide 50/53). Reproduce and report the example given in the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxyFyrmh0GUx"
   },
   "outputs": [],
   "source": [
    "def LZ_online(sequence):\n",
    "    dictionary = dict()\n",
    "    prefix = ''\n",
    "    coded_text = ''\n",
    "\n",
    "    dictionary[''] = 0\n",
    "    for symbol in sequence:\n",
    "        prefix += symbol\n",
    "        if prefix in dictionary:\n",
    "            continue\n",
    "        else: \n",
    "            prev_prefix_address = dictionary.get(prefix[0:len(prefix)-1])\n",
    "            dictionary[prefix] = len(dictionary)\n",
    "            if prev_prefix_address == None :\n",
    "                prev_prefix_address = 0\n",
    "\n",
    "            address_nb_bits = np.ceil(np.log2(len(dictionary)-1))\n",
    "            bin_format = '0' + str(int(address_nb_bits)) + 'b'\n",
    "            coded_text += (format(prev_prefix_address,bin_format) + symbol)\n",
    "            prefix = ''\n",
    "        \n",
    "    return dictionary,coded_text[1:] # remove the first character of the code that is a formating artifact\n",
    "\n",
    "LZ_online(\"1011010100010\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UG7cwbf50GUx"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Implement a function that returns the encoded sequence using the LZ77 algorithm as described by the algorithm below given an input string and a sliding window size l. Reproduce the example given in Figure 2 with window_size=7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LZ77(sequence, window_size = 7):\n",
    "    sliding_window = '' #size of window_size\n",
    "    \n",
    "    code = ''\n",
    "    i = 0\n",
    "    while i < (len(sequence)-1):\n",
    "\n",
    "        d = 0\n",
    "        p = 0\n",
    "        \n",
    "        nb_occurrences = sliding_window.count(sequence[i])\n",
    "        window_start_index = 0\n",
    "        \n",
    "        while nb_occurrences > 0:\n",
    "\n",
    "            current_d = sliding_window.index(sequence[i], window_start_index)\n",
    "            current_p = 0\n",
    "            #start longuest prefix match\n",
    "            while (i+current_p) < (len(sequence)-1) and (current_d + current_p) < len(sliding_window):\n",
    "                if sequence[i+current_p] == sliding_window[current_d + current_p]:\n",
    "                    current_p += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            if current_p >= p:\n",
    "                p = current_p\n",
    "                d = current_d\n",
    "                d = len(sliding_window) - d\n",
    "            \n",
    "            window_start_index = current_d + 1\n",
    "            nb_occurrences -= 1\n",
    "\n",
    "        i += p\n",
    "        \n",
    "        code += str(d) + str(p) + sequence[i]\n",
    "        i +=1\n",
    "        start = i-window_size if i>window_size else 0\n",
    "        sliding_window = sequence[start:i]\n",
    "        \n",
    "        \n",
    "    return code\n",
    "\n",
    "LZ77(\"abracadabrad\",7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EG1vVgUg0GUz"
   },
   "outputs": [],
   "source": [
    "# [Locked Cell] Evaluation of your functions by the examiner. \n",
    "# You don't have access to the evaluation, this will be done by the examiner.\n",
    "# Therefore, this cell will return nothing for the students.\n",
    "import os\n",
    "if os.path.isfile(\"private_evaluation.py\"):\n",
    "    from private_evaluation import unit_tests\n",
    "    unit_tests(Huffman_code, LZ_online, LZ77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "znaBCYTG0GU0"
   },
   "source": [
    "## Source coding and reversible (lossless) data compression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F_fTEp10GU0"
   },
   "outputs": [],
   "source": [
    "#import pyplot to make plots for questions like question 7\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Opening the files and put them into one line string\n",
    "text = ''\n",
    "with open('morse.txt', 'r') as file:\n",
    "    morse_text = file.read().replace('\\n', '')\n",
    "\n",
    "alphabet_text = ''\n",
    "with open('text.txt', 'r') as file:\n",
    "    alphabet_text = file.read().replace('\\n', '')\n",
    "\n",
    "def measure_len_in_bits_LZ77(code,window_size,alphabet_size):\n",
    "    len_in_bits = 0\n",
    "\n",
    "    for symbol in code:\n",
    "        if not symbol.isdigit():\n",
    "            len_in_bits +=1  #count the number of (number,number,symbol) tuples in the code\n",
    "    \n",
    "    nb_bits_window_nb = np.ceil(np.log2(window_size + 1))\n",
    "    nb_bits_symbol = np.ceil(np.log2(alphabet_size))\n",
    "    # for each symbol there are 2 numbers os size log2(win_size) plus the symbol to be coded in binary.\n",
    "    len_in_bits *= ((2 * nb_bits_window_nb) + nb_bits_symbol) \n",
    "\n",
    "    return len_in_bits\n",
    "\n",
    "def measure_len_in_bits_LZ_online(code,alphabet_size):\n",
    "\n",
    "    lz_online_len_in_bits = 0\n",
    "    for symbol in code:\n",
    "        if symbol == '0' or symbol == '1':\n",
    "            lz_online_len_in_bits += 1\n",
    "        else:\n",
    "            lz_online_len_in_bits += np.ceil(np.log2(alphabet_size))\n",
    "    return lz_online_len_in_bits\n",
    "\n",
    "def question5(text,verbose = True):\n",
    "\n",
    "    occurency_dict = {}\n",
    "\n",
    "    # loop over text and count occurrences.\n",
    "    for i in text:\n",
    "\n",
    "        if i in occurency_dict:\n",
    "            occurency_dict[i] = occurency_dict[i] + 1\n",
    "        else:\n",
    "            occurency_dict[i] = 1\n",
    "\n",
    "\n",
    "    #loop over symbols to compute their probability approximation\n",
    "    proba_dict = {}\n",
    "    for i in occurency_dict:\n",
    "        proba_dict[i] = occurency_dict[i]/len(text)\n",
    "        if(verbose):\n",
    "            print(\"Probability of symbol '\" + i + \"' is =\" + str(proba_dict[i]))\n",
    "\n",
    "    #get huffman dictionary and then code the text\n",
    "    huffman_dict = Huffman_code(proba_dict)\n",
    "    if(verbose):\n",
    "        print(\"bin huffman code for given text : \" + str(huffman_dict))\n",
    "\n",
    "    coded_text = ''\n",
    "    for i in text:\n",
    "        coded_text += huffman_dict[i]\n",
    "\n",
    "    if(verbose):\n",
    "        print('Text length in bits = ' + str(len(text) * np.ceil(np.log2(len(proba_dict)))) )\n",
    "        print('Coded text length in bits = ' + str(len(coded_text)))\n",
    "        print('Using the huffman code the compression rate is :' + str(len(coded_text)/(len(text)* np.ceil(np.log2(len(proba_dict))))) + 'bits per symbol')\n",
    "        \n",
    "    return proba_dict,huffman_dict,coded_text\n",
    "\n",
    "def question6(char_proba_dict,huffman_dict,coded_text,original_text):\n",
    "\n",
    " #weighted average length of huffman code\n",
    "    expected_average_code_len = 0.0\n",
    "    for i in huffman_dict:\n",
    "        expected_average_code_len += char_proba_dict[i] * len(huffman_dict[i])\n",
    "\n",
    "    print('The expected average code length of the produced huffman code is =' + str(expected_average_code_len) + ' bits per symbol')\n",
    "\n",
    "    empirical_average_code_len = len(coded_text)/len(original_text)\n",
    "\n",
    "    print('The empirical average code length of the produced huffman code is =' + str(empirical_average_code_len) + ' bits per symbol')\n",
    "\n",
    "    #theoretical bound is \n",
    "    theoretical_bound = 0.0\n",
    "    for i in char_proba_dict:\n",
    "        theoretical_bound += char_proba_dict[i] * np.log2(1/char_proba_dict[i]) # H(s)\n",
    "\n",
    "    print('The bounds for the average length is  :' + str(theoretical_bound) + \" <= average word length < \" + str(theoretical_bound + 1))\n",
    "\n",
    "    return\n",
    "\n",
    "def question7(original_text, huffman_code_dict, upper_text_len_bound = 500, step = 1):\n",
    "\n",
    "    emp_averages_code_lengths = np.zeros((len(original_text)))\n",
    "\n",
    "    for i in range(1,upper_text_len_bound,step):\n",
    "        print('iteration ' + str(i) + ' of ' + str(upper_text_len_bound), end =\"\\r\")\n",
    "        code = ''\n",
    "        for j in original_text[0:i]:\n",
    "            code += huffman_code_dict[j]\n",
    "\n",
    "        emp_averages_code_lengths[i] = len(code)/i\n",
    "    print('\\n Finished!', end =\"\\n\")\n",
    "\n",
    "    plt.plot(np.arange(start = 0,stop =upper_text_len_bound),emp_averages_code_lengths[0:upper_text_len_bound])\n",
    "    plt.savefig('evolution of the empirical average length.pdf', format=\"pdf\")  \n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def question11(text, window_size):\n",
    "\n",
    "    lz77_coded_morse = LZ77(text,window_size)\n",
    "    mixed_code = (question5(lz77_coded_morse, verbose=False))[2]\n",
    "    print(\"length of code in bits of mixed code = \",len(mixed_code) )\n",
    "    print(\"total compression rate with mixed code = \", (len(mixed_code)/(len(text) * 2)))\n",
    "\n",
    "    return mixed_code\n",
    "\n",
    "def question12(text):\n",
    "    \n",
    "    lz77_coded_morse = LZ77(text,1)\n",
    "    lz77_len_in_bits = measure_len_in_bits_LZ77(lz77_coded_morse,1,4)\n",
    "    print(\"lZ77 length for window size \" + str(1) + ' : ' + str(lz77_len_in_bits)) \n",
    "    print(\"lZ77 compression rate for window size \" + str(1) + ' : ' + str(lz77_len_in_bits/(len(text)*2)))\n",
    "\n",
    "    combined_coded_morse = (question5(lz77_coded_morse,verbose=False))[2]\n",
    "\n",
    "    print(\"lZ77 + H length for window size \" + str(1) + ' : ' + str(len(combined_coded_morse)))\n",
    "    print(\"lZ77 + H compression rate for window size \" + str(1) + ' : ' + str(len(combined_coded_morse)/(len(text)* 2)))\n",
    "\n",
    "    for i in range (1000, 11001, 1000):\n",
    "\n",
    "        lz77_coded_morse = LZ77(text,i)\n",
    "        lz77_len_in_bits = measure_len_in_bits_LZ77(lz77_coded_morse,i,4)\n",
    "        \n",
    "        print(\"lZ77 length for window size \" + str(i) + ' : ' + str(lz77_len_in_bits)) \n",
    "        print(\"lZ77 compression rate for window size \" + str(i) + ' : ' + str(lz77_len_in_bits/(len(text)*2)))\n",
    "\n",
    "        combined_coded_morse = (question5(lz77_coded_morse,verbose=False))[2]\n",
    "        print(\"lZ77 + H length for window size \" + str(i) + ' : ' + str(len(combined_coded_morse)))\n",
    "        print(\"lZ77 + H compression rate for window size \" + str(i) + ' : ' + str(len(combined_coded_morse)/(len(text)* 2)))\n",
    "        \n",
    "    return\n",
    "\n",
    "def question14(alphabet_text):\n",
    "    print(\"#############################\")\n",
    "    print(\"For original alphabet text:\")\n",
    "\n",
    "    alphabet_char_probabilities, alphabet_huffman_dict, alphabet_huffman_coded = question5(alphabet_text)\n",
    "    question6(alphabet_char_probabilities, alphabet_huffman_dict, alphabet_huffman_coded, alphabet_text)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "############### Q5 \n",
    "\n",
    "print(\"#############################\")\n",
    "print(\"For Morse text :\")\n",
    "morse_char_probabilities, morse_huffman_dict, morse_huffman_coded = question5(morse_text)\n",
    "\n",
    "################ Q6\n",
    " \n",
    "question6(morse_char_probabilities, morse_huffman_dict, morse_huffman_coded, morse_text)\n",
    "\n",
    "################ Q7\n",
    "\n",
    "question7(morse_text,morse_huffman_dict)\n",
    "\n",
    "################ Q8\n",
    "print(\"starting lz online\")\n",
    "_,lempel_ziv_coded_morse = LZ_online(morse_text)\n",
    "lz_online_len_in_bits = measure_len_in_bits_LZ_online(lempel_ziv_coded_morse,4)\n",
    "\n",
    "print('Length of lempel-ziv compressed code is :' + str(lz_online_len_in_bits))\n",
    "print('The compression rate of the Lempel-ziv method is =' + str(lz_online_len_in_bits/(len(morse_text) * 2)))\n",
    "\n",
    "################ Q9\n",
    "print( 'starting LZ 77')\n",
    "win_size = 7\n",
    "lz77_coded_morse = LZ77(morse_text,win_size)\n",
    "\n",
    "lz77_len_in_bits = measure_len_in_bits_LZ77(lz77_coded_morse,win_size,4)\n",
    "\n",
    "print('Length of LZ77 compressed code is :' + str(lz77_len_in_bits))\n",
    "print('The compression rate of the LZ77 method is =' + str(lz77_len_in_bits/(len(morse_text) * 2)))\n",
    "\n",
    "################ Q11\n",
    "\n",
    "print( 'starting combination of LZ77 and Huffman')\n",
    "combined_coded_morse = question11(morse_text,7)\n",
    "\n",
    "################# Q12\n",
    "\n",
    "print(\"comparison length and compression rate for diff window sizes, LZ77 and LZ77 + Huffman\")\n",
    "question12(morse_text)\n",
    "\n",
    "################# Q14\n",
    "\n",
    "question14(alphabet_text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arr1rcE65c6K"
   },
   "source": [
    "## Channel coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLwLdqlh5qE5"
   },
   "outputs": [],
   "source": [
    "# Write here your codes for questions 16 to 21 (you may delete this comment)\n",
    "# From here, you may import either opencv (cv2) or the Python Imaging Library (PIL), but no other extra libraries.\n",
    "\n",
    "from PIL import Image,ImageOps\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def read_greyscale_image(path):\n",
    "\n",
    "    img = Image.open(path) \n",
    "    if img is None:\n",
    "        sys.exit(\"Could not read the image.\")\n",
    "\n",
    "    grey_scale = ImageOps.grayscale(img)\n",
    "    display(grey_scale) \n",
    "\n",
    "    return grey_scale\n",
    "\n",
    "def save_image(img,path):\n",
    "    if img is None or path is None:\n",
    "        sys.exit(\"Could not save Image.\")\n",
    "\n",
    "    img.save(path, \"PNG\")\n",
    "\n",
    "    return\n",
    "\n",
    "def encode_image(img):\n",
    "    return np.matrix.flatten(np.unpackbits(np.asarray(img),axis = 1))\n",
    "\n",
    "def decode_image(image_as_bits,shape):\n",
    "    return np.reshape(np.packbits(image_as_bits,axis = 0),shape)\n",
    "\n",
    "def hamming_sequence_encoding(sequence):\n",
    "    #pad the sequence to be a multiple of 4\n",
    "    padding_len = len(sequence) % 4\n",
    "    np.append(sequence,np.zeros(padding_len, dtype=np.int8))\n",
    "\n",
    "    #apply hamming code to every 4 char\n",
    "    hamming_sequence = np.zeros(len(sequence)//4*7,dtype=np.int8)\n",
    "    for i in range(0,len(sequence),4):\n",
    "        code = hamming_code(sequence[i:i+4])\n",
    "\n",
    "        hamming_sequence[((i//4)*7):((i//4)*7)+7] = code\n",
    "\n",
    "    return hamming_sequence\n",
    "\n",
    "def hamming_sequence_decoding(sequence,original_nb_bits):\n",
    "    decoded_sequence = np.zeros(len(sequence)//7 * 4,dtype=np.int8)\n",
    "    nb_corrections = 0 \n",
    "\n",
    "    for i in range(0,len(sequence),7):\n",
    "        decoded_bits = decode_hamming(sequence[i:i+7])\n",
    "        if np.array_equal(decoded_bits, sequence[i:i+4]):\n",
    "            None\n",
    "        else :\n",
    "            nb_corrections += 1\n",
    "\n",
    "        decoded_sequence[(i//7) *4 : ((i//7) * 4) + 4] = decoded_bits\n",
    "        \n",
    "    #remove padding done at source\n",
    "    return decoded_sequence[0:original_nb_bits]\n",
    "\n",
    "def sequence_through_channel(original_sequence):\n",
    "    noisy_sequence = original_sequence\n",
    "\n",
    "    for i, bit in enumerate(noisy_sequence):\n",
    "        noisy_sequence[i] = noisy_channel(bit)\n",
    "\n",
    "    return noisy_sequence\n",
    "\n",
    "def noisy_channel(bit):\n",
    "    if np.random.rand() > 0.01 :\n",
    "        return bit\n",
    "    else:\n",
    "        return (bit + 1) % 2\n",
    "\n",
    "def hamming_code(bits):\n",
    "    if len(bits) != 4:\n",
    "        print('error: wrong number of bits given')\n",
    "        return None\n",
    "\n",
    "    parity = np.zeros(3,dtype=np.int8)\n",
    "    for i in range(len(parity)):\n",
    "        parity[i] = (bits[i%4] + bits[(i+1)%4] + bits[(i+2)%4]) % 2\n",
    "\n",
    "    code = np.append(bits,parity)\n",
    "    return code\n",
    "\n",
    "def decode_hamming(code):\n",
    "    if len(code) != 7:\n",
    "        print('error: wrong number of bits given')\n",
    "        return None\n",
    "\n",
    "    bits = np.copy(code[0:4])\n",
    "    received_parity = code[4:7]\n",
    "    computed_parity = (hamming_code(code[0:4]))[4:7]\n",
    "\n",
    "    syndrome = np.zeros(3,dtype=np.int8)\n",
    "    nb_errors = 0 \n",
    "\n",
    "    for i in range(len(received_parity)):\n",
    "\n",
    "        if(computed_parity[i] != received_parity[i]):\n",
    "            syndrome[i] = 1\n",
    "            nb_errors += 1\n",
    "\n",
    "    if nb_errors == 3:\n",
    "        bits[2] = (code[2] + 1) % 2\n",
    "\n",
    "    if nb_errors == 2:\n",
    "        if syndrome[0] and syndrome[1]:\n",
    "            bits[1] = (code[1] + 1) % 2\n",
    "\n",
    "        if syndrome[1] and syndrome[2]:\n",
    "            bits[3] = (code[3] + 1) % 2\n",
    "\n",
    "        if syndrome[2] and syndrome[0]:\n",
    "            bits[0] = (code[0] + 1) % 2\n",
    "\n",
    "    return bits\n",
    "\n",
    "\n",
    "def number_of_differences(seq1,seq2):\n",
    "    nb_diff = 0\n",
    "    for i in range(len(seq1)):\n",
    "        if seq1[i] != seq2[i]:\n",
    "            nb_diff += 1\n",
    "    \n",
    "    return nb_diff\n",
    "\n",
    "def naive_hamming_seq_decoding(sequence,original_nb_bits):\n",
    "\n",
    "    decoded_sequence = np.zeros(len(sequence)//7 * 4,dtype=np.int8)\n",
    "\n",
    "    for i in range(0,len(sequence),7):\n",
    "        decoded_sequence[(i//7) *4 : ((i//7) * 4) + 4] = sequence[i:i+4]\n",
    "        \n",
    "    #remove padding done at source\n",
    "    return decoded_sequence[0:original_nb_bits]\n",
    "\n",
    "######################################## Code to answer the questions ##############\n",
    "\n",
    "#### 16 :Load image and show ####################\n",
    "\n",
    "original_image = read_greyscale_image(\"image.png\")\n",
    "\n",
    "#### 17 :Encode image using 1byte/pixel #########\n",
    "\n",
    "image_as_sequence = encode_image(original_image)\n",
    "\n",
    "#### 18 :Simulate channel and decode sequence ###\n",
    "im_width, im_height = original_image.size\n",
    "\n",
    "after_channel = decode_image(sequence_through_channel(image_as_sequence),(im_height,im_width))\n",
    "display(Image.fromarray(after_channel))\n",
    "\n",
    "save_image(Image.fromarray(after_channel),'noisy.png')\n",
    "\n",
    "#### 19 :Encode image using Hamming code #########\n",
    "hamming_sequence = hamming_sequence_encoding(image_as_sequence)\n",
    "\n",
    "#### 20 :Simulate channel on Hamming sequence ####\n",
    "hamming_after_channel = sequence_through_channel(hamming_sequence)\n",
    "\n",
    "decoded_hamming = hamming_sequence_decoding(hamming_after_channel,len(image_as_sequence))\n",
    "naive_decoded_hamming = naive_hamming_seq_decoding(hamming_after_channel,len(image_as_sequence))\n",
    "\n",
    "print(\"errors without hamming decoding compared to original image = \" + str(number_of_differences(image_as_sequence, naive_decoded_hamming)))\n",
    "print(\"errors with  hamming decoding compared to original image = \" + str(number_of_differences(image_as_sequence, decoded_hamming)))\n",
    "\n",
    "display(Image.fromarray(decode_image(decoded_hamming,(im_height,im_width))))\n",
    "save_image(Image.fromarray(decode_image(decoded_hamming,(im_height,im_width))),'postHamming_decoded.png')\n",
    "save_image(Image.fromarray(decode_image(naive_decoded_hamming,(im_height,im_width))),'naive_Hamming_decoding.png')\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "P2 - Notebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "3656675e5c9ddbad44bbaefbc4c978fb0abed373f282a0307983d4ade1822146"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('iml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
